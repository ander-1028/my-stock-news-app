import streamlit as st
import pandas as pd
from gnews import GNews
import jieba
import twstock
from FinMind.data import DataLoader
import datetime
import os
import re
import yfinance as yf
import math
import json

# --- Constants & Mapping ---
# Sources for financial news to ensure quality
FINANCIAL_SOURCES = "(å·¥å•†æ™‚å ± OR ç¶“æ¿Ÿæ—¥å ± OR ç§‘æŠ€æ–°å ± OR é‰…äº¨ç¶² OR æ•¸ä½æ™‚ä»£)"

DEFAULT_INDUSTRY_MAP = {
    "AI èˆ‡ ä¼ºæœå™¨": [
        ("å°ç©é›»", "2330"), ("é´»æµ·", "2317"), ("å»£é”", "2382"), ("ç·¯å‰µ", "3231"), 
        ("æŠ€å˜‰", "2376"), ("å‹¤èª ", "2359"), ("å·æ¹–", "2059"), ("é›™é´»", "3324"), ("å¥‡é‹", "3017")
    ],
    "åŠå°é«”": [
        ("å°ç©é›»", "2330"), ("è¯é›»", "2303"), ("è¯ç™¼ç§‘", "2454"), ("æ—¥æœˆå…‰æŠ•æ§", "3711"), 
        ("ä¸–èŠ¯-KY", "3661"), ("å‰µæ„", "3443"), ("äº¬å…ƒé›»å­", "2449")
    ],
    "è»å·¥èˆ‡èˆªå¤ª": [
        ("æ¼¢ç¿”", "2634"), ("é¾å¾·é€ èˆ¹", "6753"), ("é›·è™", "8033"), ("å…¨è¨Š", "5222"), 
        ("ä¸­ä¿¡é€ èˆ¹", "2644"), ("å¯¶ä¸€", "8222"), ("äºèˆª", "2630")
    ],
    "ä½è»Œè¡›æ˜Ÿ": [
        ("æ˜‡é”ç§‘", "3491"), ("å•Ÿç¢", "6285"), ("é‡‘åƒé›»", "2368"), ("è€€è¯", "2367"), 
        ("è¯é€š", "2313"), ("å°æš", "2314"), ("è²¿è¯-KY", "3665")
    ],
    "ç›£æ§æ¸…å–®": []
}

MAP_FILE = "my_industry_map.json"

def load_industry_map():
    """Load industry map from JSON if exists, otherwise return default."""
    if os.path.exists(MAP_FILE):
        try:
            with open(MAP_FILE, "r", encoding="utf-8") as f:
                saved_map = json.load(f)
                # Convert list [name, code] back to tuple (name, code)
                return {k: [tuple(v) for v in val] for k, val in saved_map.items()}
        except Exception as e:
            st.error(f"é è®€æ¸…å–®ç™¼ç”ŸéŒ¯èª¤: {e}")
    return DEFAULT_INDUSTRY_MAP.copy()

def save_industry_map(industry_map):
    """Save industry map to JSON."""
    try:
        with open(MAP_FILE, "w", encoding="utf-8") as f:
            json.dump(industry_map, f, ensure_ascii=False, indent=4)
    except Exception as e:
        st.error(f"å„²å­˜æ¸…å–®ç™¼ç”ŸéŒ¯èª¤: {e}")

# --- Configuration & Setup ---
st.set_page_config(page_title="å°ç£è‚¡å¸‚æ–°èåˆ†æèˆ‡å¸‚å ´æ¦‚æ³", layout="wide", page_icon="ğŸ“ˆ")

# Function to safely get secrets
def get_secret(key):
    try:
        val = st.secrets.get(key)
        if val: return val
    except Exception:
        pass
    return os.environ.get(key)

# --- Cached Fetching Functions ---

@st.cache_data(ttl=3600)
def fetch_institutional_data_cached(api_token, start_date, end_date):
    """Cached function to fetch FinMind data."""
    dl = DataLoader()
    if api_token:
        try:
            dl.login_by_token(api_token=api_token)
            df = dl.taiwan_stock_institutional_investors(
                start_date=start_date,
                end_date=end_date
            )
            return df
        except Exception as e:
            return pd.DataFrame()
    return pd.DataFrame()

@st.cache_data(ttl=3600)
def fetch_market_quotes_cached(symbols_tuple):
    """Cached function to fetch yfinance data."""
    data = []
    for symbol in symbols_tuple:
        try:
            ticker = yf.Ticker(symbol)
            hist = ticker.history(period="2d")
            if not hist.empty:
                current_price = hist['Close'].iloc[-1]
                prev_close = hist['Close'].iloc[-2] if len(hist) > 1 else current_price
                change = current_price - prev_close
                pct_change = (change / prev_close) * 100 if prev_close != 0 else 0
                data.append({
                    "ä»£ç¢¼": symbol,
                    "æœ€æ–°åƒ¹æ ¼": round(current_price, 2),
                    "æ¼²è·Œé‡‘é¡": round(change, 2),
                    "æ¼²è·Œå¹… (%)": f"{pct_change:+.2f}%"
                })
        except Exception:
            continue
    return pd.DataFrame(data)

@st.cache_data(ttl=600)
def fetch_news_data_cached(query=None):
    """Cached function to fetch GNews data with maximum transparency."""
    try:
        # Use explicit TW and zh-Hant settings
        google_news = GNews(language='zh-Hant', country='TW', period='24h', max_results=50)
        
        if query:
            # Strictly use user input without modification
            news = google_news.get_news(query)
        else:
            # Default fallback news
            news = google_news.get_news('å°ç£ è‚¡å¸‚')
            
        return news if news else []
    except Exception as e:
        st.error(f"GNews æŠ“å–ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

@st.cache_data(ttl=600)
def get_stock_price_cached(code):
    """Quickly fetch stock price for concept stocks."""
    try:
        symbol = f"{code}.TW"
        ticker = yf.Ticker(symbol)
        hist = ticker.history(period="2d")
        if not hist.empty:
            curr = hist['Close'].iloc[-1]
            prev = hist['Close'].iloc[-2] if len(hist) > 1 else curr
            change_pct = ((curr - prev) / prev) * 100 if prev != 0 else 0
            return curr, change_pct
    except:
        pass
    return None, None

# --- Classes ---

class StockMatcher:
    def __init__(self):
        self.company_to_code = {}
        self._initialize_stock_data()
        
    def _initialize_stock_data(self):
        """Initialize stock mapping from twstock and optimize jieba."""
        # Load all stocks and ETFs
        for code, info in twstock.codes.items():
            if info.type in ['è‚¡ç¥¨', 'ETF']:
                self.company_to_code[info.name] = code
                # Add company names to jieba dictionary for better segmentation
                jieba.add_word(info.name)
        
    def extract_stocks(self, text):
        """
        Identify matches in text.
        Returns a list of tuples: (Stock Name, Stock Code)
        """
        matches = []
        # Optimization: use jieba cut to match words instead of substring search if possible,
        # but substring is safer for short names.
        # Given performance, we will stick to naive iteration for now but optimized by jieba add_word
        
        # Actually, iterating 2000+ companies for every headline might be slow.
        # Let's try to match against jieba segments.
        words = set(jieba.lcut(text))
        
        for name, code in self.company_to_code.items():
            # Check if full name is in text (more accurate)
            if name in text:
                 matches.append(f"{name}({code})")
        
        return list(set(matches))

    def is_stock_related(self, text):
        return len(self.extract_stocks(text)) > 0

class MarketDataFetcher:
    def __init__(self):
        self.api_token = get_secret("FINMIND_TOKEN")
            
    def get_market_summary(self):
        """Get today's institutional investors data summary using cached fetch."""
        try:
            today = datetime.date.today()
            start_date = (today - datetime.timedelta(days=3)).strftime('%Y-%m-%d')
            end_date = today.strftime('%Y-%m-%d')
            
            df = fetch_institutional_data_cached(self.api_token, start_date, end_date)
            
            if df.empty:
                return None, "æŸ¥ç„¡è¿‘æ—¥æ³•äººæ•¸æ“š (æˆ– API éŒ¯èª¤)"
                
            latest_date = df['date'].max()
            dashboard_df = df[df['date'] == latest_date]
            summary = dashboard_df.groupby('name')[['buy', 'sell']].sum()
            summary['net'] = summary['buy'] - summary['sell']
            
            return summary, latest_date
        except Exception as e:
            return None, str(e)

def get_industry_info(text, industry_map):
    """Detect industry from text and return associated stocks."""
    keywords = {
        "AI èˆ‡ ä¼ºæœå™¨": ["ä¼ºæœå™¨", "AI", "Server", "è¼é”", "NVIDIA", "é‹ç®—"],
        "åŠå°é«”": ["åŠå°é«”", "æ™¶åœ“", "å°ç©é›»", "IC", "æ™¶ç‰‡", "Semiconductor"],
        "è»å·¥èˆ‡èˆªå¤ª": ["è»å·¥", "èˆªå¤ª", "é£›æ©Ÿ", "åœ‹é˜²", "é€ èˆ¹", "é›·è™"],
        "ä½è»Œè¡›æ˜Ÿ": ["ä½è»Œè¡›æ˜Ÿ", "ä½è»Œ", "è¡›æ˜Ÿ", "SpaceX", "Starlink"]
    }
    for industry, keys in keywords.items():
        if any(k.lower() in text.lower() for k in keys):
            return industry, industry_map.get(industry, [])
    return None, None

def detect_supply_chain_action(text):
    """Detect supply chain actions in text."""
    actions = ["æ‰“å…¥", "åˆ‡å…¥", "ä¾›æ‡‰", "ç²è¨‚å–®", "ä¾›æ‡‰éˆ", "é€²è»", "åˆä½œ"]
    return any(a in text for a in actions)

class MarketQuoteFetcher:
    def __init__(self):
        self.symbols_map = {
            "^TWII": "å°è‚¡å¤§ç›¤",
            "2330.TW": "å°ç©é›»",
            "AAPL": "è˜‹æœ (AAPL)",
            "NVDA": "è¼é” (NVDA)"
        }

    def fetch_quotes(self):
        try:
            symbols_tuple = tuple(self.symbols_map.keys())
            df = fetch_market_quotes_cached(symbols_tuple)
            
            if not df.empty:
                # Add human readable names back to the cached dataframe
                df['è‚¡ç¥¨åç¨±'] = df['ä»£ç¢¼'].map(self.symbols_map)
                # Reorder columns
                cols = ["è‚¡ç¥¨åç¨±", "ä»£ç¢¼", "æœ€æ–°åƒ¹æ ¼", "æ¼²è·Œé‡‘é¡", "æ¼²è·Œå¹… (%)"]
                return df[cols]
            return df
        except Exception as e:
            st.error(f"è¡Œæƒ…è™•ç†å¤±æ•—: {e}")
            return pd.DataFrame()

# --- Main App Logic ---

def intelligent_extract_company(title):
    """
    Intelligently extract company name and code from title.
    Rules:
    1. Text inside brackets (e.g. "å°ç©é›»").
    2. Nouns before action verbs like "æ‰“å…¥", "ä¾›è²¨", "ä¾›æ‡‰".
    """
    # 1. Brackets check
    bracket_match = re.search(r'[(ï¼ˆ]([^)ï¼‰0-9]{2,6})[)ï¼‰]', title)
    if bracket_match:
        return bracket_match.group(1), ""
    
    # 2. Action verb check
    for verb in ["æ‰“å…¥", "ä¾›è²¨", "ä¾›æ‡‰", "ä¾›æ‡‰éˆ", "åˆ‡å…¥"]:
        if verb in title:
            # Simple take first 2-4 chars before verb as company name
            idx = title.find(verb)
            if idx > 2:
                name = title[max(0, idx-3):idx].strip()
                # Clean up punctuation
                name = re.sub(r'[^\w\s]', '', name)
                return name, ""
                
    return "", ""

def main():
    st.title("ğŸ“ˆ å°ç£è‚¡å¸‚æ–°èåˆ†æèˆ‡å¸‚å ´æ¦‚æ³")
    
    # Initialize modes & session state
    if 'mode' not in st.session_state:
        st.session_state.mode = 'search' # Default mode
    if 'last_query' not in st.session_state:
        st.session_state.last_query = ""
    if 'search_input' not in st.session_state:
        st.session_state.search_input = ""
    
    if 'matcher' not in st.session_state:
        st.session_state.matcher = StockMatcher()
    
    if 'industry_map' not in st.session_state:
        st.session_state.industry_map = load_industry_map()

    # Callbacks for cleaner state management
    def set_industry_mode(ind):
        st.session_state.mode = "industry"
        st.session_state.selected_industry = ind
        st.session_state.search_input = "" # Clear search
        
    def set_search_mode():
        st.session_state.mode = "search"

    # --- Sidebar ---
    with st.sidebar:
        st.header("ğŸ” æœå°‹èˆ‡ç¯©é¸")
        # Ensure key="search_input" and logic for mode
        search_query = st.text_input("é—œéµå­—æœå°‹ (ä¾‹å¦‚: å°ç©é›», ç‡Ÿæ”¶)", key="search_input")
        if search_query:
            st.session_state.mode = "search"
        
        sort_order = st.selectbox(
            "æ’åºæ–¹å¼",
            ["æ™‚é–“ç”±æ–°åˆ°èˆŠ", "æ™‚é–“ç”±èˆŠåˆ°æ–°"]
        )
        
        if st.button("ğŸš€ é¡¯ç¤ºä»Šæ—¥æœ€æ–°æ¦‚æ³", on_click=set_search_mode):
            st.session_state.show_quotes = True

        st.markdown("---")
        st.header("ğŸš€ ç”¢æ¥­å³æ™‚è¶¨å‹¢")
        
        # Display as buttons as requested for "Industry Real-time News"
        cols = st.columns(2)
        industries = list(st.session_state.industry_map.keys())
        for i, ind in enumerate(industries):
            with cols[i % 2]:
                st.button(ind, key=f"ind_btn_{i}", on_click=set_industry_mode, args=(ind,))

        if st.session_state.mode == "industry":
            st.button("â¬…ï¸ è¿”å›æœå°‹æ¨¡å¼", on_click=set_search_mode)
            
        st.markdown("---")
        st.header("ğŸŒ™ æ³•äººæ•¸æ“š")
        if st.button("ä»Šæ—¥ä¸‰å¤§æ³•äººè²·è³£è¶…"):
            st.session_state.show_summary = True

        st.markdown("---")
        st.info("è³‡æ–™ä¾†æº: GNews, FinMind, Twstock, yfinance")

    # --- Market Quotes Section ---
    if st.session_state.get('show_quotes', False):
        st.subheader("ğŸš€ ä»Šæ—¥æœ€æ–°ç†±é–€è‚¡ç¥¨è¡Œæƒ…")
        with st.spinner("æ­£åœ¨ç²å–æœ€æ–°å³æ™‚æ•¸æ“š..."):
            quote_fetcher = MarketQuoteFetcher()
            quotes_df = quote_fetcher.fetch_quotes()
            
            if not quotes_df.empty:
                # Top metrics for indices/big stocks
                m1, m2, m3 = st.columns(3)
                # Show Index, TSMC, NVDA as highlights
                def get_row(df, sym): return df[df['ä»£ç¢¼'] == sym].iloc[0] if sym in df['ä»£ç¢¼'].values else None
                
                idx_row = get_row(quotes_df, "^TWII")
                tsmc_row = get_row(quotes_df, "2330.TW")
                nvda_row = get_row(quotes_df, "NVDA")
                
                if idx_row is not None:
                    m1.metric(idx_row['è‚¡ç¥¨åç¨±'], f"{idx_row['æœ€æ–°åƒ¹æ ¼']:,}", idx_row['æ¼²è·Œå¹… (%)'])
                if tsmc_row is not None:
                    m2.metric(tsmc_row['è‚¡ç¥¨åç¨±'], f"{tsmc_row['æœ€æ–°åƒ¹æ ¼']:,}", tsmc_row['æ¼²è·Œå¹… (%)'])
                if nvda_row is not None:
                    m3.metric(nvda_row['è‚¡ç¥¨åç¨±'], f"{nvda_row['æœ€æ–°åƒ¹æ ¼']:,}", nvda_row['æ¼²è·Œå¹… (%)'])
                
                st.write("")
                st.dataframe(quotes_df, use_container_width=True, hide_index=True)
            
            if st.button("é—œé–‰è¡Œæƒ…"):
                st.session_state.show_quotes = False
        st.divider()

    # --- Industry Analysis Mode ---
    if st.session_state.mode == "industry":
        industry = st.session_state.get('selected_industry', industries[0] if industries else "AI èˆ‡ ä¼ºæœå™¨")
        st.subheader(f"ğŸš€ {industry} - ç”¢æ¥­è¶¨å‹¢åˆ†æ")
        
        # Display Concept Stocks List
        concept_stocks = st.session_state.industry_map.get(industry, [])
        st.info(f"ğŸ’¡ **{industry} æ¦‚å¿µè‚¡æ¸…å–®ï¼š** " + "ã€".join([f"{name}({code})" for name, code in concept_stocks]))
        
        # Quick price check columns
        price_cols = st.columns(min(len(concept_stocks), 5))
        for i, (name, code) in enumerate(concept_stocks[:5]): # Show first 5 in metrics
            with price_cols[i % 5]:
                price, pct = get_stock_price_cached(code)
                if price:
                    st.metric(name, f"{price:.1f}", f"{pct:+.2f}%")
        
        # Fetch industry specific news
        with st.spinner(f"æ­£åœ¨æŠ“å– {industry} ç›¸é—œé«˜å“è³ªè²¡ç¶“æ–°è..."):
            industry_news = fetch_news_data_cached(industry)
            
            if industry_news:
                for item in industry_news[:5]: # Show top 5
                    with st.expander(f"ğŸ“Œ {item.get('title', 'ç„¡æ¨™é¡Œ')}"):
                        st.write(item.get('description', 'å…§å®¹è¼‰å…¥ä¸­...'))
                        st.markdown(f"[é–±è®€å…¨æ–‡]({item.get('url')})")
                
                # Full list with clickable price check
                st.write("**ğŸ” å³æ™‚è‚¡åƒ¹é€£å‹• (é»æ“Šå€‹è‚¡æŸ¥è©¢):**")
                p_cols = st.columns(min(len(concept_stocks), 4))
                for i, (name, code) in enumerate(concept_stocks):
                    with p_cols[i % 4]:
                        if st.button(f"ğŸ’µ {name} ({code})", key=f"btn_{code}"):
                            p, c = get_stock_price_cached(code)
                            if p:
                                st.write(f"ğŸ’° {p:.1f} ({c:+.2f}%)")
                            else:
                                st.write("æŸ¥ç„¡è‚¡åƒ¹")
            else:
                st.warning("ç›®å‰ç„¡ç›¸é—œé‡å¤§ç”¢æ¥­æ–°èã€‚")
        
        if st.button("çµæŸç”¢æ¥­åˆ†æ"):
            st.session_state.mode = "search"
            st.rerun()
        st.divider()
    
    elif st.session_state.mode == "search":
        # --- News Fetching & Processing (Search Mode) ---
        
        # Trigger fetch if first run or query changed
        should_fetch = False
        if 'raw_news' not in st.session_state or not st.session_state.raw_news:
            should_fetch = True
        if search_query != st.session_state.last_query:
            should_fetch = True
            st.session_state.last_query = search_query

        if should_fetch:
            with st.spinner("æ­£åœ¨æœå°‹æ–°è..."):
                # Strictly direct query
                st.session_state.raw_news = fetch_news_data_cached(search_query if search_query else None)
                st.session_state.page_number = 1 

        all_news = st.session_state.raw_news
        
        # Debug section disabled per user request
        if not all_news:
            st.info("è«‹å˜—è©¦æ›´æ›é—œéµå­—ï¼Œç›®å‰æŸ¥ç„¡è³‡æ–™")
            return 

        # No strict filtering by stock ID - show all but identify stocks for labeling
        final_news = []
        matcher = st.session_state.matcher
        
        for item in all_news:
            title = item.get('title', '')
            # Only label, don't filter
            item['related_stocks'] = matcher.extract_stocks(title)
            final_news.append(item)
                
        # --- Sorting ---
        if sort_order == "æ™‚é–“ç”±æ–°åˆ°èˆŠ":
             try:
                final_news.sort(key=lambda x: pd.to_datetime(x.get('published date', '2000-01-01')), reverse=True)
             except:
                pass
        else:
             try:
                final_news.sort(key=lambda x: pd.to_datetime(x.get('published date', '2000-01-01')), reverse=False)
             except:
                pass

        # --- Display with Pagination ---
        total_items = len(final_news)
        items_per_page = 10
        total_pages = math.ceil(total_items / items_per_page)
        
        st.success(f"æ‰¾åˆ° {total_items} å‰‡ç›¸é—œæ–°è")
            
        # Pagination Control
        if 'page_number' not in st.session_state:
            st.session_state.page_number = 1
                
        if st.session_state.page_number > total_pages:
            st.session_state.page_number = 1

        start_idx = (st.session_state.page_number - 1) * items_per_page
        end_idx = start_idx + items_per_page
        page_items = final_news[start_idx:end_idx]
        
        # Display Items
        for item in page_items:
            with st.container(border=True): # Use border for clarity
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.markdown(f"### [{item['title']}]({item['url']})")
                    st.caption(f"ç™¼å¸ƒæ™‚é–“: {item.get('published date', 'æœªçŸ¥')}")
                with col2:
                    if item.get('related_stocks'):
                        st.write(" ".join([f"`{s}`" for s in item['related_stocks']]))
                    else:
                        st.info("ç„¡æ¨™è¨»å€‹è‚¡")
                
                # Industry smart detection
                ind_name, ind_stocks = get_industry_info(item['title'] + item.get('description', ''), st.session_state.industry_map)
                if ind_name:
                    st.info(f"âœ¨ **{ind_name} ä¾›æ‡‰éˆè¿½è¹¤ï¼š** " + "ã€".join([f"{n}({c})" for n, c in ind_stocks]))
                else:
                    st.caption("ï¿½ æ­¤å…¬å¸å°šæœªæ­¸é¡ï¼Œå¯æ‰‹å‹•åŠ å…¥é—œæ³¨æ¸…å–®æˆ–ç”¢æ¥­ã€‚")
                
                # --- Universal Supply Chain Update Tool ---
                with st.expander("ğŸ› ï¸ å±•é–‹æ›´æ–°å·¥å…·"):
                    st.write("ğŸš€ **ç™¼ç¾æ½›åœ¨ç”¢æ¥­æ©Ÿæœƒï¼Ÿ** æ‚¨å¯ä»¥æ‰‹å‹•æ›´æ–°è¿½è¹¤æ¸…å–®ã€‚")
                    
                    related_stocks = item.get('related_stocks', [])
                    target_name, target_code = "", ""
                    
                    if related_stocks:
                        target_full = related_stocks[0] 
                        match = re.match(r"(.*?)\((.*?)\)", target_full)
                        if match:
                            target_name, target_code = match.groups()
                    
                    if not target_name:
                        ext_name, ext_code = intelligent_extract_company(item['title'])
                        target_name = ext_name
                        target_code = ext_code

                    st.write("---")
                    st.write("ç¢ºèªå…¬å¸è³‡è¨Šï¼š")
                    fc1, fc2 = st.columns(2)
                    with fc1: target_name = st.text_input("å…¬å¸åç¨±", value=target_name, key=f"n_in_{item['url']}")
                    with fc2: target_code = st.text_input("è‚¡ç¥¨ä»£ç¢¼", value=target_code, key=f"c_in_{item['url']}")

                    if target_name:
                        if st.button(f"â• åŠ å…¥æˆ‘çš„ç›£æ§æ¸…å–®", key=f"mon_btn_{item['url']}"):
                            if "ç›£æ§æ¸…å–®" not in st.session_state.industry_map:
                                st.session_state.industry_map["ç›£æ§æ¸…å–®"] = []
                            if (target_name, target_code) not in st.session_state.industry_map["ç›£æ§æ¸…å–®"]:
                                st.session_state.industry_map["ç›£æ§æ¸…å–®"].append((target_name, target_code))
                                save_industry_map(st.session_state.industry_map)
                                st.toast(f"ğŸ“º å·²å°‡ {target_name} åŠ å…¥ç›£æ§æ¸…å–®", icon="ğŸ“¡")
                            st.rerun()

                        tab_ex, tab_new = st.tabs(["åŠ å…¥ç¾æœ‰ç”¢æ¥­", "å»ºç«‹æ–°ä¸»é¡Œ"])
                        with tab_ex:
                            current_inds = [ind for ind in st.session_state.industry_map.keys() if ind != "ç›£æ§æ¸…å–®"]
                            if current_inds:
                                target_ind = st.selectbox("é¸æ“‡ç›®æ¨™ç”¢æ¥­", current_inds, key=f"sel_ind_{item['url']}")
                                if st.button("ç¢ºèªåŠ å…¥ç”¢æ¥­", key=f"cf_add_{item['url']}"):
                                    if (target_name, target_code) not in st.session_state.industry_map[target_ind]:
                                        st.session_state.industry_map[target_ind].append((target_name, target_code))
                                        save_industry_map(st.session_state.industry_map)
                                        st.toast(f"âœ… å·²å°‡ {target_name} åŠ å…¥ {target_ind}ï¼", icon="ğŸš€")
                                    st.rerun()
                        with tab_new:
                            new_theme = st.text_input("æ–°ç”¢æ¥­åç¨±", key=f"new_th_{item['url']}")
                            if st.button("å»ºç«‹ä¸¦åŠ å…¥", key=f"cf_new_{item['url']}"):
                                if new_theme:
                                    if new_theme not in st.session_state.industry_map:
                                        st.session_state.industry_map[new_theme] = [(target_name, target_code)]
                                        save_industry_map(st.session_state.industry_map)
                                        st.toast(f"âœ¨ å·²å»ºç«‹æ–°ä¸»é¡Œ {new_theme}", icon="ğŸ†•")
                                    st.rerun()
                
                st.markdown("<br>", unsafe_allow_html=True) # Spacer

        # --- Pagination UI at bottom ---
        if total_pages > 1:
            st.divider()
            c1, c2, c3 = st.columns([1, 2, 1])
            with c1:
                if st.session_state.page_number > 1:
                    if st.button("ä¸Šé "):
                        st.session_state.page_number -= 1
                        st.rerun()
            with c2:
                st.markdown(f"<div style='text-align: center'> ç¬¬ {st.session_state.page_number} / {total_pages} é  </div>", unsafe_allow_html=True)
            with c3:
                if st.session_state.page_number < total_pages:
                    if st.button("ä¸‹é "):
                        st.session_state.page_number += 1
                        st.rerun()

        # Move Summary Section here to show in search mode as an overlay if active
        if st.session_state.get('show_summary', False):
            st.markdown("---")
            st.subheader("ğŸ§ æ¯æ—¥å¸‚å ´æ¦‚æ³å›é¡§")
            token = get_secret("FINMIND_TOKEN")
            if not token:
                st.warning("âš ï¸ æœªåµæ¸¬åˆ° FINMIND_TOKEN")
            else:
                fetcher = MarketDataFetcher()
                summary_df, msg = fetcher.get_market_summary()
                if summary_df is not None:
                    st.caption(f"è³‡æ–™æ—¥æœŸ: {msg}")
                    cols = st.columns(min(len(summary_df), 4))
                    for idx, (name, row) in enumerate(summary_df.iterrows()):
                        if idx >= 4: break
                        with cols[idx]:
                            st.metric(name, f"{int(row['net']/1000000):,}M", f"{int(row['net']/1000):,}K")
            if st.button("é—œé–‰æ¦‚æ³"):
                st.session_state.show_summary = False
            st.divider()

if __name__ == "__main__":
    main()
