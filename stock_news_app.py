import subprocess
import sys

def install_and_import(pkg_name, import_name=None):
    # å¦‚æœæ²’æœ‰æŒ‡å®š import åç¨±ï¼Œå°±é è¨­èˆ‡å®‰è£åç¨±ç›¸åŒ
    if import_name is None:
        import_name = pkg_name
        
    try:
        # æª¢æŸ¥æ˜¯å¦å·²ç¶“å®‰è£
        __import__(import_name)
    except ImportError:
        print(f"æ‰¾ä¸åˆ°å¥—ä»¶ {import_name}ï¼Œæ­£åœ¨ç‚ºæ‚¨è‡ªå‹•å®‰è£ {pkg_name}...")
        try:
            # åŸ·è¡Œå®‰è£æŒ‡ä»¤
            subprocess.check_call([sys.executable, "-m", "pip", "install", pkg_name])
            print(f"{pkg_name} å®‰è£æˆåŠŸï¼")
        except Exception as e:
            print(f"å®‰è£ {pkg_name} å¤±æ•—: {e}")
# è¨­å®šéœ€è¦å®‰è£çš„æ¸…å–®ï¼š (å®‰è£å¥—ä»¶åç¨±, ç¨‹å¼ç¢¼å…§importçš„åç¨±)
required_packages = [
    ("gnews", "gnews"),
    ("streamlit", "streamlit"),
    ("pandas", "pandas"),
    ("jieba", "jieba"),
    ("lxml", "lxml"),
    ("twstock", "twstock"),
    ("scikit-learn", "sklearn")  # é€™è£¡æœ€é‡è¦ï¼šå®‰è£å« scikit-learnï¼Œç¨‹å¼å…§å« sklearn
]

for pkg_name, import_name in required_packages:
    install_and_import(pkg_name, import_name)

print("\n--- ç’°å¢ƒæª¢æŸ¥å®Œæˆï¼Œæº–å‚™åŸ·è¡Œä¸»ç¨‹å¼ ---")

import streamlit as st
import pandas as pd
from gnews import GNews
import jieba
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import twstock
import time



# --- Configuration & Setup ---
st.set_page_config(page_title="å°ç£æ–°èä¸»é¡Œåˆ†ç¾¤èˆ‡å€‹è‚¡è­˜åˆ¥", layout="wide")

class StockMatcher:
    def __init__(self):
        self.company_to_code = {}
        self._initialize_stock_data()

    def _initialize_stock_data(self):
        """Initialize stock mapping from twstock."""
        # twstock.codes contains details for all stocks
        # We want to map Company Name -> Stock Code
        # We will try to match full name and likely the stock name if available
        # Note: twstock.codes is a dict where key is code, value is tuple/namedtuple
        
        # Example structure update might be needed depending on twstock version, 
        # but generally keys are codes.
        
        for code, info in twstock.codes.items():
            # info usually has type, name, ISIN, start, market, group, etc.
            # We focus on 'name'
            if info.type in ['è‚¡ç¥¨', 'ETF']: # Filter for stocks and ETFs if desired
                self.company_to_code[info.name] = code

    def extract_stocks(self, text):
        """
        Identify matches in text.
        Returns a list of tuples: (Stock Name, Stock Code)
        """
        matches = []
        # Naive matching: iterate all companies. 
        # Optimization: Could build a trie or use Aho-Corasick if performance issues arise.
        # For now, simple iteration is acceptable for POC.
        for name, code in self.company_to_code.items():
            if name in text:
                matches.append(f"{name}({code})")
        
        return list(set(matches)) # Deduplicate

class NewsClusterer:
    def __init__(self):
        self.vectorizer = TfidfVectorizer(tokenizer=jieba.cut, stop_words=None, max_features=1000)
        self.kmeans = None
    
    def fetch_news(self, period='24h'):
        google_news = GNews(language='zh-Hant', country='TW', period=period, max_results=100)
        news = google_news.get_news('å°ç£è‚¡å¸‚') # Search specifically for market relevant news or general 'å°ç£'
        # If 'å°ç£è‚¡å¸‚' is too narrow, we can try just getting top news, but GNews requires a topic or query often for best results.
        # Let's try to get general business/market news or just top news if query is empty.
        if not news:
           # Fallback or broader search
           news = google_news.get_news('è²¡ç¶“')
        return news
    
    def cluster_news(self, df, n_clusters=5):
        if df.empty:
            return df
        
        # Vectorize
        # Preprocessing: remove non-chinese chars could help but might remove stock codes 
        # (though we match stock names which are usually Chinese).
        tfidf_matrix = self.vectorizer.fit_transform(df['title'])
        
        # Clustering
        # Ensure we don't ask for more clusters than samples
        true_k = min(n_clusters, len(df) - 1) if len(df) > 1 else 1
        if true_k < 2:
             df['cluster'] = 0
             return df

        self.kmeans = KMeans(n_clusters=true_k, random_state=42)
        self.kmeans.fit(tfidf_matrix)
        
        df['cluster'] = self.kmeans.labels_
        return df

# --- Main App Logic ---

def main():
    st.title("ğŸ“° å°ç£æ–°èä¸»é¡Œåˆ†ç¾¤èˆ‡å€‹è‚¡è­˜åˆ¥ç³»çµ±")
    st.markdown("""
    æœ¬ç³»çµ±è‡ªå‹•æŠ“å–æœ€æ–°å°ç£æ–°èï¼Œåˆ©ç”¨ AI æŠ€è¡“é€²è¡Œä¸»é¡Œåˆ†ç¾¤ï¼Œä¸¦è‡ªå‹•è­˜åˆ¥æ–°èä¸­æåŠçš„ä¸Šå¸‚æ«ƒå…¬å¸ã€‚
    """)

    # Sidebar Controls
    with st.sidebar:
        st.header("è¨­å®š")
        n_clusters = st.slider("åˆ†ç¾¤æ•¸é‡ (Topics)", min_value=3, max_value=12, value=6)
        fetch_btn = st.button("ğŸ”„ æŠ“å–æœ€æ–°æ–°è")
        
        st.info("è³‡æ–™ä¾†æº: GNews (24h)\nNLP: Jieba + TF-IDF + K-Means\nè‚¡ç¥¨è³‡æ–™: twstock")

    if 'news_data' not in st.session_state:
        st.session_state.news_data = pd.DataFrame()

    if fetch_btn:
        with st.spinner("æ­£åœ¨æŠ“å–æ–°èä¸¦é€²è¡Œåˆ†æ..."):
            # 1. Initialize
            matcher = StockMatcher()
            clusterer = NewsClusterer()
            
            # 2. Fetch
            raw_news = clusterer.fetch_news()
            
            if not raw_news:
                st.error("æœªèƒ½æŠ“å–åˆ°æ–°èï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
            else:
                # Convert to DataFrame
                df = pd.DataFrame(raw_news)
                # Keep relevant columns: title, published date, url
                df = df[['title', 'published date', 'url']]
                
                # 3. Cluster
                df = clusterer.cluster_news(df, n_clusters)
                
                # 4. Stock Match
                df['related_stocks'] = df['title'].apply(lambda x: matcher.extract_stocks(x))
                df['has_stock'] = df['related_stocks'].apply(lambda x: len(x) > 0)
                
                st.session_state.news_data = df
                st.success(f"æˆåŠŸæŠ“å– {len(df)} å‰‡æ–°èï¼Œåˆ†ç‚º {n_clusters} å€‹ç¾¤çµ„ï¼")

    # Display Results
    if not st.session_state.news_data.empty:
        df = st.session_state.news_data
        
        # Metrics
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ç¸½æ–°èæ•¸", len(df))
        with col2:
            st.metric("æåŠè‚¡ç¥¨çš„æ–°èæ•¸", df['has_stock'].sum())

        st.divider()

        # Group viewing
        # Get cluster counts to show in selectbox
        cluster_counts = df['cluster'].value_counts().sort_index()
        cluster_options = {f"ç¾¤çµ„ {i} ({count} å‰‡)": i for i, count in cluster_counts.items()}
        
        selected_option = st.selectbox("é¸æ“‡ä¸»é¡Œç¾¤çµ„", list(cluster_options.keys()))
        selected_cluster_id = cluster_options[selected_option]
        
        # Filter data
        filtered_df = df[df['cluster'] == selected_cluster_id].copy()
        
        # Display as a clean table/list
        st.subheader(f"ğŸ“Œ {selected_option}")
        
        for idx, row in filtered_df.iterrows():
            with st.container():
                # Title with link
                st.markdown(f"**[{row['title']}]({row['url']})**")
                
                # Stocks pills
                if row['related_stocks']:
                    st.write("ğŸ“ˆ é—œè¯å€‹è‚¡:", " ".join([f"`{s}`" for s in row['related_stocks']]))
                else:
                    st.caption("ç„¡ç›¸é—œè‚¡ç¥¨")
                
                st.caption(f"ç™¼å¸ƒæ™‚é–“: {row['published date']}")
                st.divider()

if __name__ == "__main__":
    main()
