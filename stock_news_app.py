import streamlit as st
import pandas as pd
from gnews import GNews
import jieba
import twstock
from FinMind.data import DataLoader
import datetime
import math
import os
import yfinance as yf

# --- Configuration & Setup ---
st.set_page_config(page_title="å°ç£è‚¡å¸‚æ–°èåˆ†æèˆ‡å¸‚å ´æ¦‚æ³", layout="wide", page_icon="ğŸ“ˆ")

# Function to safely get secrets
def get_secret(key):
    try:
        # Truly safe access to st.secrets
        # We don't even check 'if key in st.secrets' as that might trigger it
        val = st.secrets.get(key)
        if val: return val
    except Exception:
        pass
    return os.environ.get(key)

# --- Classes ---

class StockMatcher:
    def __init__(self):
        self.company_to_code = {}
        self._initialize_stock_data()
        
    def _initialize_stock_data(self):
        """Initialize stock mapping from twstock and optimize jieba."""
        # Load all stocks and ETFs
        for code, info in twstock.codes.items():
            if info.type in ['è‚¡ç¥¨', 'ETF']:
                self.company_to_code[info.name] = code
                # Add company names to jieba dictionary for better segmentation
                jieba.add_word(info.name)
        
    def extract_stocks(self, text):
        """
        Identify matches in text.
        Returns a list of tuples: (Stock Name, Stock Code)
        """
        matches = []
        # Optimization: use jieba cut to match words instead of substring search if possible,
        # but substring is safer for short names.
        # Given performance, we will stick to naive iteration for now but optimized by jieba add_word
        
        # Actually, iterating 2000+ companies for every headline might be slow.
        # Let's try to match against jieba segments.
        words = set(jieba.lcut(text))
        
        for name, code in self.company_to_code.items():
            # Check if full name is in text (more accurate)
            if name in text:
                 matches.append(f"{name}({code})")
        
        return list(set(matches))

    def is_stock_related(self, text):
        return len(self.extract_stocks(text)) > 0

class MarketDataFetcher:
    def __init__(self):
        self.api_token = get_secret("FINMIND_TOKEN")
        self.dl = DataLoader()
        if self.api_token:
            try:
                self.dl.login_by_token(api_token=self.api_token)
            except Exception as e:
                st.error(f"FinMind Login å¤±æ•—: {e}")
            
    def get_market_summary(self):
        """Get today's institutional investors data summary."""
        try:
            # FinMind data is usually updated end of day. 
            # If running early in the day, we might need yesterday's data.
            today = datetime.date.today()
            # Try to catch last 3 days to ensure we get data (holidays etc)
            start_date = (today - datetime.timedelta(days=3)).strftime('%Y-%m-%d')
            end_date = today.strftime('%Y-%m-%d')
            
            df = self.dl.taiwan_stock_institutional_investors(
                start_date=start_date,
                end_date=end_date
            )
            
            if df.empty:
                return None, "æŸ¥ç„¡è¿‘æ—¥æ³•äººæ•¸æ“š (å¯èƒ½ç‚ºå‡æ—¥æˆ–å°šæœªæ›´æ–°)"
                
            # Filter for latest date
            latest_date = df['date'].max()
            dashboard_df = df[df['date'] == latest_date]
            
            # Summarize by type (Foreign, Investment Trust, Dealer)
            summary = dashboard_df.groupby('name')[['buy', 'sell']].sum()
            summary['net'] = summary['buy'] - summary['sell']
            
            return summary, latest_date
            
        except Exception as e:
            return None, str(e)

class MarketQuoteFetcher:
    def __init__(self):
        self.symbols = {
            "^TWII": "å°è‚¡å¤§ç›¤",
            "2330.TW": "å°ç©é›»",
            "2454.TW": "è¯ç™¼ç§‘",
            "AAPL": "è˜‹æœ (AAPL)",
            "NVDA": "è¼é” (NVDA)"
        }

    def fetch_quotes(self):
        data = []
        try:
            for symbol, name in self.symbols.items():
                ticker = yf.Ticker(symbol)
                # Use fast_info or history if info is slow
                hist = ticker.history(period="2d")
                if not hist.empty:
                    current_price = hist['Close'].iloc[-1]
                    prev_close = hist['Close'].iloc[-2] if len(hist) > 1 else current_price
                    change = current_price - prev_close
                    pct_change = (change / prev_close) * 100 if prev_close != 0 else 0
                    
                    data.append({
                        "è‚¡ç¥¨åç¨±": name,
                        "ä»£ç¢¼": symbol,
                        "æœ€æ–°åƒ¹æ ¼": round(current_price, 2),
                        "æ¼²è·Œé‡‘é¡": round(change, 2),
                        "æ¼²è·Œå¹… (%)": f"{pct_change:+.2f}%"
                    })
                else:
                    data.append({"è‚¡ç¥¨åç¨±": name, "ä»£ç¢¼": symbol, "æœ€æ–°åƒ¹æ ¼": "ç„¡æ•¸æ“š", "æ¼²è·Œé‡‘é¡": "-", "æ¼²è·Œå¹… (%)": "-"})
            return pd.DataFrame(data)
        except Exception as e:
            st.error(f"è¡Œæƒ…æŠ“å–å¤±æ•—: {e}")
            return pd.DataFrame()

# --- Main App Logic ---

def main():
    st.title("ğŸ“ˆ å°ç£è‚¡å¸‚æ–°èåˆ†æèˆ‡å¸‚å ´æ¦‚æ³")
    
    # Initialize classes
    if 'matcher' not in st.session_state:
        st.session_state.matcher = StockMatcher()
    
    # --- Sidebar ---
    with st.sidebar:
        st.header("ğŸ” æœå°‹èˆ‡ç¯©é¸")
        search_query = st.text_input("é—œéµå­—æœå°‹ (ä¾‹å¦‚: å°ç©é›», ç‡Ÿæ”¶)")
        
        sort_order = st.selectbox(
            "æ’åºæ–¹å¼",
            ["æ™‚é–“ç”±æ–°åˆ°èˆŠ", "æ™‚é–“ç”±èˆŠåˆ°æ–°"]
        )
        
        st.markdown("---")
        st.header("ğŸŒ™ å¸‚å ´æ¦‚æ³")
        if st.button("ä»Šæ—¥å¸‚å ´æ¦‚æ³å›é¡§"):
            st.session_state.show_summary = True
            
        st.header("ğŸ“ˆ å³æ™‚è¡Œæƒ…")
        if st.button("ğŸš€ é¡¯ç¤ºä»Šæ—¥æœ€æ–°è¡Œæƒ…"):
            st.session_state.show_quotes = True

        st.markdown("---")
        st.info("è³‡æ–™ä¾†æº: GNews, FinMind, Twstock, yfinance")

    # --- Market Quotes Section ---
    if st.session_state.get('show_quotes', False):
        st.subheader("ğŸš€ ä»Šæ—¥æœ€æ–°ç†±é–€è‚¡ç¥¨è¡Œæƒ…")
        with st.spinner("æ­£åœ¨ç²å–æœ€æ–°å³æ™‚æ•¸æ“š..."):
            quote_fetcher = MarketQuoteFetcher()
            quotes_df = quote_fetcher.fetch_quotes()
            
            if not quotes_df.empty:
                # Top metrics for indices/big stocks
                m1, m2, m3 = st.columns(3)
                # Show Index, TSMC, NVDA as highlights
                def get_row(df, sym): return df[df['ä»£ç¢¼'] == sym].iloc[0] if sym in df['ä»£ç¢¼'].values else None
                
                idx_row = get_row(quotes_df, "^TWII")
                tsmc_row = get_row(quotes_df, "2330.TW")
                nvda_row = get_row(quotes_df, "NVDA")
                
                if idx_row is not None:
                    m1.metric(idx_row['è‚¡ç¥¨åç¨±'], f"{idx_row['æœ€æ–°åƒ¹æ ¼']:,}", idx_row['æ¼²è·Œå¹… (%)'])
                if tsmc_row is not None:
                    m2.metric(tsmc_row['è‚¡ç¥¨åç¨±'], f"{tsmc_row['æœ€æ–°åƒ¹æ ¼']:,}", tsmc_row['æ¼²è·Œå¹… (%)'])
                if nvda_row is not None:
                    m3.metric(nvda_row['è‚¡ç¥¨åç¨±'], f"{nvda_row['æœ€æ–°åƒ¹æ ¼']:,}", nvda_row['æ¼²è·Œå¹… (%)'])
                
                st.write("")
                st.dataframe(quotes_df, use_container_width=True, hide_index=True)
            
            if st.button("é—œé–‰è¡Œæƒ…"):
                st.session_state.show_quotes = False
        st.divider()

    # --- Market Summary Section ---
    if st.session_state.get('show_summary', False):
        st.subheader("ğŸ§ æ¯æ—¥å¸‚å ´æ¦‚æ³å›é¡§")
        token = get_secret("FINMIND_TOKEN")
        
        if not token:
            st.warning("âš ï¸ æœªåµæ¸¬åˆ° FINMIND_TOKENï¼Œç„¡æ³•ç²å–è©³ç´°æ³•äººæ•¸æ“šã€‚")
            st.info("è«‹æ–¼ .streamlit/secrets.toml ä¸­è¨­å®š FINMIND_TOKEN='æ‚¨çš„å¯†é‘°'")
            if st.button("é—œé–‰æ¦‚æ³ "):
                st.session_state.show_summary = False
        else:
            fetcher = MarketDataFetcher()
            summary_df, msg = fetcher.get_market_summary()
            
            if summary_df is not None:
                st.caption(f"è³‡æ–™æ—¥æœŸ: {msg}")
                
                # Display metrics
                cols = st.columns(len(summary_df.head(4)))
                for idx, (name, row) in enumerate(summary_df.iterrows()):
                    if idx >= 4: break
                    net = row['net']
                    
                    with cols[idx]:
                        st.metric(
                            label=name,
                            value=f"{int(net/1000000):,}M",
                            delta=f"{int(net/1000):,}K"
                        )
            else:
                st.warning(f"ç„¡æ³•å–å¾—å¸‚å ´æ•¸æ“š: {msg}")
            
            if st.button("é—œé–‰æ¦‚æ³"):
                st.session_state.show_summary = False
        st.divider()

    # --- News Fetching & Processing ---
    
    # We store fetched news in session state to avoid refetching on every interaction
    if 'raw_news' not in st.session_state:
        st.session_state.raw_news = []
        
    # Auto-fetch logic or button? The spec implies "Search" triggers it, 
    # but initially we should verify if we have data.
    # Let's add a "Fetch" button effectively but also auto-fetch on load if empty?
    # User spec: "æŒ‰ä¸‹æœå°‹å¾Œ...". So maybe a fetch button is better or just auto-update on input change.
    # To save API calls, let's use a explicit button or cache.
    # Given the flow, let's auto-fetch generic news if empty, and filter when 'search' changes.
    
    if not st.session_state.raw_news:
         with st.spinner("æ­£åœ¨è¼‰å…¥æœ€æ–°è²¡ç¶“æ–°è..."):
            try:
                google_news = GNews(language='zh-Hant', country='TW', period='24h', max_results=50)
                # Retry different queries
                news = google_news.get_news('å°ç£ è‚¡å¸‚')
                if not news:
                    news = google_news.get_news('å°è‚¡')
                if not news:
                    news = google_news.get_top_news()
                
                st.session_state.raw_news = news if news else []
            except Exception as e:
                st.error(f"æŠ“å–æ–°èå¤±æ•—: {e}")
                st.session_state.raw_news = []

    # Apply Search & Filter
    all_news = st.session_state.raw_news
    
    # 1. Search Query
    if search_query:
        # If user types a query, maybe we should fetch NEW data from GNews for that query?
        # Specification says: "æŒ‰ä¸‹æœå°‹å¾Œï¼Œç¨‹å¼éœ€å…ˆæ ¹æ“šé—œéµå­—éæ¿¾ gnews çµæœ"
        # Since we only fetched 100 items 'general', filtering locally might yield 0 results.
        # It's better to refetch if query exists.
        pass # Optimization: decide if refetch or local filter. 
        # For this implementation, let's refetch if query changes to ensure we get relevant news.
    
    # Simple Local Filter first for responsiveness if just sorting
    filtered_news = []
    
    # Logic: If search query is present, we might want to REFRETCH from GNews with that query 
    # because the generic 'å°ç£ è‚¡å¸‚' list might not have specific keywords.
    # But to avoid complexity of state management, let's stick to local filtering first 
    # OR provide a "Refresh/Search" button. 
    # Let's add a "Search" button in sidebar to make it explicit if fetching new data.
    # User said: "æŒ‰ä¸‹æœå°‹å¾Œ...". 
    
    # Let's refetch if we detect a change in intention, but standard UI just filters.
    # Standard GNews usage:
    # If search_query is provided, filter the existing list. 
    
    for item in all_news:
        if search_query and search_query not in item['title']:
            continue
        filtered_news.append(item)
        
    # 2. Smart Filtering (Stock Only)
    final_news = []
    matcher = st.session_state.matcher
    
    for item in filtered_news:
        # Some items might not have 'title' if GNews structure changes
        title = item.get('title', '')
        stocks = matcher.extract_stocks(title)
        if stocks:
            item['related_stocks'] = stocks
            final_news.append(item)
    
    # Debug info (only if dev mode or similar, but let's show success message with details)
    # st.write(f"æŠ“å– {len(all_news)} å‰‡ï¼Œé—œéµå­—éæ¿¾å¾Œ {len(filtered_news)} å‰‡ï¼Œå€‹è‚¡è­˜åˆ¥å¾Œ {len(final_news)} å‰‡")
            
    # 3. Sorting
    if sort_order == "æ™‚é–“ç”±æ–°åˆ°èˆŠ":
         # GNews usually returns newest first, but let's ensure
         # Format check: 'published date' is str like 'Mon, 20 Jan 2026 ...'
         # Parsing dates can be tricky. GNews returns standardized format.
         try:
            final_news.sort(key=lambda x: pd.to_datetime(x['published date']), reverse=True)
         except:
            pass # Keep default order if parse fails
    else:
         try:
            final_news.sort(key=lambda x: pd.to_datetime(x['published date']), reverse=False)
         except:
            pass

    # --- Display with Pagination ---
    total_items = len(final_news)
    items_per_page = 10
    total_pages = math.ceil(total_items / items_per_page)
    
    if total_items == 0:
        st.info("æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„èˆ‡ã€Œå°ç£ä¸Šå¸‚æ«ƒå…¬å¸ã€ç›¸é—œçš„æ–°èã€‚")
    else:
        st.success(f"æ‰¾åˆ° {total_items} å‰‡ç›¸é—œæ–°è")
        
        # Pagination Control
        if 'page_number' not in st.session_state:
            st.session_state.page_number = 1
            
        # Reset page if filter changes drastically (naive check: if page > total_pages)
        if st.session_state.page_number > total_pages:
            st.session_state.page_number = 1

        # Calculate slice
        start_idx = (st.session_state.page_number - 1) * items_per_page
        end_idx = start_idx + items_per_page
        page_items = final_news[start_idx:end_idx]
        
        # Display Items
        for item in page_items:
            with st.container():
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.markdown(f"### [{item['title']}]({item['url']})")
                    st.caption(f"ç™¼å¸ƒæ™‚é–“: {item['published date']}")
                with col2:
                    st.write(" ".join([f"`{s}`" for s in item['related_stocks']]))
                st.divider()

        # Pagination Buttons
        if total_pages > 1:
            st.write("---")
            # Centered columns for pagination
            cols = st.columns(total_pages + 2) # Just simple number buttons
            # Limit number of buttons if too many pages? For now assume < 10 pages reasonable.
            
            # Simple Prev/Next + Current Page indicator
            c1, c2, c3 = st.columns([1, 2, 1])
            with c1:
                if st.session_state.page_number > 1:
                    if st.button("â¬…ï¸ ä¸Šä¸€é "):
                        st.session_state.page_number -= 1
                        st.rerun()
            with c2:
                st.markdown(f"<div style='text-align: center'> ç¬¬ {st.session_state.page_number} / {total_pages} é  </div>", unsafe_allow_html=True)
            with c3:
                if st.session_state.page_number < total_pages:
                    if st.button("ä¸‹ä¸€é  â¡ï¸"):
                        st.session_state.page_number += 1
                        st.rerun()

if __name__ == "__main__":
    main()
